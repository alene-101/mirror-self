# -*- coding: utf-8 -*-
"""YAHH.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/191MhErHHZ5UP6v4KFEFW9M0DfBOg2YiU
"""

!pip install -q transformers accelerate torch pandas

from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
import torch

model_name = "microsoft/Phi-3-mini-4k-instruct"

print("Loading Microsoft Phi-3-mini model...")
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,
    device_map="auto"
)

chatbot = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    max_new_tokens=512,
    temperature=0.7,
    top_p=0.9
)

print("Model loaded successfully!")

SYSTEM_PROMPT = """
You are a professional educational planning assistant.

Your role:
- Help students transform a large learning goal into smaller, time-bound subgoals.
- Each subgoal must have a title, description, realistic deadline, and useful learning resources.

Rules:
1. Input: main goal and duration (weeks).
2. Output: 3–7 smaller goals that form a logical learning progression.
3. Each goal must include:
   - "title": short and action-oriented (verbs like Learn, Practice, Review)
   - "description": concise and instructional
   - "deadline": format YYYY-MM-DD (evenly spaced from today)
   - "resources": list of 1–3 recommended materials or links
4. Base deadlines on today’s date.
5. Return only JSON in this format:

{
  "main_goal": "...",
  "subgoals": [
    {
      "title": "...",
      "description": "...",
      "deadline": "YYYY-MM-DD",
      "resources": ["...", "..."]
    }
  ]
}

Do NOT output markdown, explanations, or greetings.
Return clean JSON only.
"""

def generate_response(history, user_input):
    """
    history: list of (user, bot) messages
    user_input: current user message
    """
    full_context = SYSTEM_PROMPT + "\n\nConversation so far:\n"
    for turn in history:
        full_context += f"User: {turn['user']}\nAssistant: {turn['bot']}\n"
    full_context += f"User: {user_input}\nAssistant:"

    response = chatbot(full_context)[0]["generated_text"]

    if "Assistant:" in response:
        response = response.split("Assistant:")[-1].strip()

    return response

print("Study Planner Chatbot is ready! (type 'exit' to quit)\n")

history = []

while True:
    user_input = input("You: ").strip()
    if user_input.lower() in ["exit", "quit"]:
        print("Goodbye! Study smart!")
        break

    bot_reply = generate_response(history, user_input)
    history.append({"user": user_input, "bot": bot_reply})
    print(f"Bot: {bot_reply}\n")